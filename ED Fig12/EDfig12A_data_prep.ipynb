{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import pandas as pd                                                    \n",
    "import numpy as np                                                     \n",
    "import scanpy as sc                                                                                 \n",
    "from time import time                                                       \n",
    "import sys\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from anndata import AnnData, read_h5ad, concat\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "# from xlrd import open_workbook\n",
    "\n",
    "def read_xlsx(file, sheet_name=None, header=None):\n",
    "    excel = pd.ExcelFile(load_workbook(file), engine=\"openpyxl\")\n",
    "    sheet_name = sheet_name or excel.sheet_names[0]\n",
    "    sheet = excel.book[sheet_name]\n",
    "    df = excel.parse(sheet_name, header=header)\n",
    "\n",
    "    for item in sheet.merged_cells:\n",
    "        top_col, top_row, bottom_col, bottom_row = item.bounds\n",
    "        base_value = item.start_cell.value\n",
    "        top_row -= 1\n",
    "        top_col -= 1\n",
    "        if header is not None:\n",
    "            top_row -= header + 1\n",
    "            bottom_row -= header + 1\n",
    "        df.iloc[top_row:bottom_row, top_col:bottom_col] = base_value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw15 = read_h5ad(\"../source_data/gw15.h5ad\"); gw15 = gw15.raw.to_adata()\n",
    "gw20 = read_h5ad(\"../source_data/gw20.h5ad\"); gw20 = gw20.raw.to_adata()\n",
    "gw22 = read_h5ad(\"../source_data/gw22.h5ad\"); gw22 = gw22.raw.to_adata()\n",
    "gw34 = read_h5ad(\"../source_data/gw34.h5ad\"); gw34 = gw34.raw.to_adata()\n",
    "\n",
    "gw15.obs['H3_annotation'] = gw15.obs['H3_annotation'].astype(str).where(gw15.obs['H3_annotation'].notna(), gw15.obs['H2_annotation'].astype(str) + '-c0')\n",
    "gw20.obs['H3_annotation'] = gw20.obs['H3_annotation'].astype(str).where(gw20.obs['H3_annotation'].notna(), gw20.obs['H2_annotation'].astype(str) + '-c0')\n",
    "gw22.obs['H3_annotation'] = gw22.obs['H3_annotation'].astype(str).where(gw22.obs['H3_annotation'].notna(), gw22.obs['H2_annotation'].astype(str) + '-c0')\n",
    "gw34.obs['H3_annotation'] = gw34.obs['H3_annotation'].astype(str).where(gw34.obs['H3_annotation'].notna(), gw34.obs['H2_annotation'].astype(str) + '-c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(adata):\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.scale(adata, max_value=6)\n",
    "    return adata    \n",
    "\n",
    "gw15 = preprocess(gw15)\n",
    "gw20 = preprocess(gw20)\n",
    "gw22 = preprocess(gw22)\n",
    "gw34 = preprocess(gw34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_region(gw):\n",
    "    gw.obs['region'] = gw.obs['region'].str[0]\n",
    "    gw = gw[gw.obs['region'].isin(['F', 'P', 'O'])]\n",
    "    return gw\n",
    "\n",
    "gw15 = extract_region(gw15)\n",
    "gw20 = extract_region(gw20)\n",
    "gw22 = extract_region(gw22)\n",
    "gw34 = extract_region(gw34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_group = read_xlsx(\"EN groups based on sankey.xlsx\", header=0)\n",
    "\n",
    "def rep_cluster(name):\n",
    "    return name.replace(\" cluster \", \"-c\")\n",
    "\n",
    "key_lst = [\"clusters from GW15\", \"clusters from GW20\", \"clusters from GW22\", \"clusters from GW34\"]\n",
    "data_lst = [\"gw15\", \"gw20\", \"gw22\", \"gw34\"]\n",
    "# key_lst = [\"clusters from GW34\"]\n",
    "# data_lst = [\"gw34_raw\"]\n",
    "for i in range(len(key_lst)):\n",
    "    key = key_lst[i]\n",
    "    group_dict = {rep_cluster(en_group[key][i]): en_group['Group name'][i] for i in range(en_group.shape[0]) if not pd.isna(en_group[key][i]) }\n",
    "    locals()[data_lst[i]].obs['group'] = locals()[data_lst[i]].obs['H3_annotation'].map(group_dict)\n",
    "    locals()[data_lst[i]] = locals()[data_lst[i]][~pd.isna(locals()[data_lst[i]].obs['group'])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_scale = concat([gw15, gw20, gw22, gw34], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_group(gw, group):\n",
    "    if group == \"'EN-IT-L5/6\":\n",
    "        gw15_sub = gw[(gw.obs.H3_annotation.isin([\"EN-IT-L5/6-c1\", \"EN-IT-L5/6-c2\",\n",
    "                                       \"EN-IT-L5/6-c3\", \"EN-IT-L5-c1\",\n",
    "                                       \"EN-IT-L5-c2\", \"EN-IT-L5-c3\"]))\n",
    "                   & (gw.obs.gw == '15')]\n",
    "        gw_other = gw[(gw.obs.group == group) & (gw.obs.H1_annotation != '15')]\n",
    "        gw_group = concat([gw15_sub, gw_other], axis=0)\n",
    "    elif group == \"'EN-IT-L4\":\n",
    "        gw15_sub = gw[(gw.obs.H3_annotation.isin([\"EN-IT-L3/4-1-c1\"]))\n",
    "                    & (gw.obs.gw == '15')]\n",
    "        gw_other = gw[(gw.obs.group == group) & (gw.obs.H1_annotation != '15')]\n",
    "        gw_group = concat([gw15_sub, gw_other], axis=0)\n",
    "    elif group == \"'EN-IT-L3\":\n",
    "        gw15_sub = gw[(gw.obs.H3_annotation.isin([\"EN-IT-L3/4-1-c1\", \"EN-IT-L5/6-c1\"]))\n",
    "                    & (gw.obs.gw == '15')]\n",
    "        gw_other = gw[(gw.obs.group == group) & (gw.obs.H1_annotation != '15')]\n",
    "        gw_group = concat([gw15_sub, gw_other], axis=0)\n",
    "    elif group == \"'EN-IT-L2\":\n",
    "        gw15_sub = gw[(gw.obs.H3_annotation.isin([\"EN-IT-L3/4-1-c1\"]))\n",
    "                    & (gw.obs.gw == '15')]\n",
    "        gw_other = gw[(gw.obs.group == group) & (gw.obs.H1_annotation != '15')]\n",
    "        gw_group = concat([gw15_sub, gw_other], axis=0)\n",
    "    else:\n",
    "        gw_group = gw[gw.obs.group == group]\n",
    "    return gw_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_lst = ['F', 'P', 'O']\n",
    "def zs_calcu(gw, group):\n",
    "    gw_group = extract_group(gw_scale, group)\n",
    "    gw_mean_lst = []\n",
    "    for area in area_lst:\n",
    "        gw_zs = gw_group[ (gw_group.obs['gw'] == str(gw)) & (gw_group.obs['source'] == area)]\n",
    "        gw_mean = np.mean(gw_zs.X, axis=0)\n",
    "        gw_mean_lst.append(gw_mean)\n",
    "    gw_mean_lst = np.array(gw_mean_lst)\n",
    "    return gw_mean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/Users/shunzhou/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"result/figs8\", exist_ok=True)\n",
    "\n",
    "group_lst = [\"'EN-ET-L5/6\", \"'EN-ET-SP/L6b\", \"'EN-IT-L2\", \"'EN-IT-L3\", \"'EN-IT-L4\", \"'EN-IT-L5/6\"]\n",
    "\n",
    "for i in range(len(group_lst)):\n",
    "    group = group_lst[i]\n",
    "    gw15_zs = zs_calcu(15, group)\n",
    "    gw20_zs = zs_calcu(20, group)\n",
    "    gw22_zs = zs_calcu(22, group)\n",
    "    gw34_zs = zs_calcu(34, group)\n",
    "    gw_zs = pd.DataFrame(np.concatenate([gw15_zs, gw20_zs, gw22_zs, gw34_zs], axis=0))\n",
    "    gw_zs.columns = gw_scale.var.index\n",
    "    gw_zs['area'] = area_lst * 4\n",
    "    gw_zs['gw'] = np.repeat(['gw15', 'gw20', 'gw22', 'gw34'], 3)\n",
    "    group_name = group\n",
    "    group_name = group_name[1:len(group_name)]\n",
    "    if \"/\" in group_name:\n",
    "        group_name = group_name.replace('/','|')\n",
    "    gw_zs.to_csv(f\"result/figs8/{group_name}_zs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
